<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8" />
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1.0, shrink-to-fit=no">
<!-- <link href="assets/images/diamond.png" rel="icon" /> -->
<title>CS184 Final Project: Improving Path Tracing with VCM (Vertex Connection and Merging)</title>
<meta name="description" content="184 Final Project Proposal">
<meta name="author" content="harnishdesign.net">

<!-- Stylesheet
============================== -->
<!-- Bootstrap -->
<link rel="stylesheet" type="text/css" href="assets/vendor/bootstrap/css/bootstrap.min.css" />
<!-- Font Awesome Icon -->
<link rel="stylesheet" type="text/css" href="assets/vendor/font-awesome/css/all.min.css" />
<!-- Magnific Popup -->
<link rel="stylesheet" type="text/css" href="assets/vendor/magnific-popup/magnific-popup.min.css" />
<!-- Highlight Syntax -->
<link rel="stylesheet" type="text/css" href="assets/vendor/highlight.js/styles/github.css" />
<!-- Custom Stylesheet -->
<link rel="stylesheet" type="text/css" href="assets/css/stylesheet.css" />
</head>

<body data-spy="scroll" data-target=".idocs-navigation" data-offset="125">

<!-- Preloader -->
<div class="preloader">
  <div class="lds-ellipsis">
    <div></div>
    <div></div>
    <div></div>
    <div></div>
  </div>
</div>
<!-- Preloader End --> 

<!-- Document Wrapper   
=============================== -->
<div id="main-wrapper"> 
  
  <!-- Header
  ============================ -->
  <header id="header" class="sticky-top"> 
    <!-- Navbar -->
    <nav class="primary-menu navbar navbar-expand-lg navbar-dropdown-dark">
      <div class="container-fluid">
        <!-- Sidebar Toggler -->
		<button id="sidebarCollapse" class="navbar-toggler d-block d-md-none" type="button"><span></span><span class="w-75"></span><span class="w-50"></span></button>
		
		<!-- Logo --> 
        <!-- <a class="logo ml-md-3" href="index.html" title="iDocs Template"> <img src="assets/images/logo.png" alt="iDocs Template"/> </a>  -->
		<span class="text-2 ml-2">Team Members: Nico Castaneda, Jasmine Lin, Jennifer Prince, David Camacho</span> 
        <!-- Logo End -->
    </nav>
    <!-- Navbar End --> 
  </header>
  <!-- Header End --> 
  
  <!-- Content
  ============================ -->
  <div id="content" role="main">
    
	<!-- Sidebar Navigation
	============================ -->
	<div class="idocs-navigation bg-light">
      <ul class="nav flex-column ">
        <!-- <li class="nav-item"><a class="nav-link active" href="#idocs_start">Overview</a>
        	<ul class="nav flex-column">
	        	<li class="nav-item"><a class="nav-link" href="index.html">Overview</a></li>
			</ul>
        </li> -->
        <li class="nav-item"><a class="nav-link" href="#idocs_layout"> Final Report </a>
          <ul class="nav flex-column">
			<li class="nav-item"><a class="nav-link" href="#idocs_header">Final Report</a></li>
			<li class="nav-item"><a class="nav-link" href="#idocs_navbar">Video and Slides</a></li>
          </ul>
        </li>
      </ul>
    </div>
    
    <!-- Docs Content
	============================ -->
    <div class="idocs-content">
      <div class="container"> 		
        
		<hr class="divider">
		
		<!-- Final Project: Milestone
		============================ -->
        <section id="idocs_layout">
		  <h1>Vertex Connection Merging Final Report </h1>
		</p>
        </section>
		
        <!-- Report
		============================ -->
        <section id="idocs_header">
          <h2>Final Report</h2>

          <!-- Abstract -->
          <h3>Abstract</h3>
          <p>
            For our final project, we present a more robust path tracing technique that can render highly specular scenes with specular and glossy light transport. 
            This technique, vertex connection and merging (VCM), was implemented into our code from project 3 (parts 1 and 2) and can be extended into two parts - 
            photon mapping and bidirectional path tracing. With this implementation, we were able to render more unique lighting effects, specifically caustics and 
            other effects from different media, as well as reduce the amount of noise in our images. 
          </p>

          <div id="centerImage">
			<img src="img/technical_image.png" width="700px" style="margin: 5px 5px 5px 5px;">
            <figcaption>To showcase the two steps that make up VCM. </figcaption>
			<figcaption>Image Source: http://iliyan.com/publications/ImplementingVCM  </figcaption>	
		  </div>

          <!-- Technical Approach -->
          <h3>Technical Approach</h3>

          <h5>Photon Mapping</h5>
          <p>
            Using pure path tracing, it would be computationally infeasible to get caustic lighting effects. To remedy this issue, we can use photon mapping - a 
            technique that simulates the behavior of light in a 3D scene. With photon mapping, we can break our rendering step into two passes: the map construction 
            and rendering. 
          </p>
          <p>
            During our first pass, during the construction, we start tracing a large number of photons (which can be considered to be virtual particles of light) from 
            different light sources in the scene. By tracing the direction of the photons, we can keep track of where they intersect with the surfaces in the scene and 
            track it in a data structure called a photon map. Once the surface intersection occurs, we can use Russian Roulette to determine if we want to absorb or reflect 
            the photon in a new direction. For the photon map, it was organized in the fashion of a balanced kd-tree. For our implementation, the kd-tree was built with a 
            single sorting step at the beginning, and with these optimizations, it can help our algorithm run faster. 
          </p>
          <p>
            In our second pass, for rendering, we use our photon map to estimate the radiance of each pixel in our output image. Specifically speaking, we use the nearby 
            photons of a certain pixel (which is determined through the nearest neighbors algorithm) to estimate the amount of light that is reflected or transmitted and 
            this would ultimately affect the contribution towards the final color and brightness of the pixel. This breaks down our radiance at a pixel into three components: 
            direct lighting, indirect lighting, and caustic lighting. Direct lighting was calculated using the same method as in projects 3-2 and 3-1, while indirect and caustic lighting were
            calculated by getting the average of the 100 nearest photons to the desired point. We also found that we ended up with sharper renders if we only used the indirect lighting Photon
            map under a certain ray depth, so the first few calculations actually still used at_least_one_bounce_radiance. There was also special calculations for specular surfaces with regards to
            the photon map, as instead of directly using the photon map, we recurse until we get a diffuse surface to reflect off of the specular material.
          </p>

          <p>
            The main resources we used that helped our implementation can be found <a href="http://www.cs.cmu.edu/afs/cs/academic/class/15462-s15/www/lec_slides/lec16.pdf">here</a> and 
            <a href="https://www.cs.cmu.edu/afs/cs/academic/class/15462-s09/www/lec/17/lec17.pdf">here</a> (we primarily used these resources to conceptually understand what photon mapping 
            was doing and to provide with us some kind of structure for our implementation). 
          </p>

          <p>
            However, while the integration of photon mapping helps tremendously, at least in comparison to the original path tracing implementation, photon mapping still 
            has its flaws, and can produce blurry caustics based on the distribution of photons. In addition, the amount of noise in the renders can also be reduced with 
            the addition of bidirectional path tracing. 
          </p>

          <h5>Bidirectional Path Tracing</h5>
          <p>
            At its core, bidirectional path tracing is a light transport algorithm - more specifically, you shoot a path from the eye (camera in this case) and the light 
            and connect every pair of vertices along the path. As an extension of the original path tracing algorithm in project 3, it traces the ray of light from both 
            the camera and the light sources in the scene and then connects them at the point of where they intersect - otherwise known as a vertex. Once these vertices are 
            connected, bidirectional path tracing is able to produce more realistic lighting effects (such as caustics and more complicated light paths) as it is able to 
            determine where the light bounces around the scene. More information on bidirectional path tracing can be found 
            <a href="https://graphics.stanford.edu/courses/cs348b-03/papers/veach-chapter10.pdf">here</a> (one of our references). 
          </p>

          <p>
            The implementation for the BDPT algorithm was taken from <a href="https://cescg.org/wp-content/uploads/2018/04/Vlnas-Bidirectional-Path-Tracing-1.pdf">here</a>. 
            Generally speaking, this is the algorithm that we followed when implementing bidirectional path tracing (found in the “Implementation” section). The algorithm was 
            done in the original <code>pathtracer.cpp</code> file and can be summarized along the following points: 
            <ul>
                <li>
                    We can split the algorithm into two parts, one where we generate all the light paths and one where we generate all the paths from the virtual camera. 
                </li>
                <li>
                    We first start generating our light paths, with a specific number. For all our light paths, we generate a light sample (i.e. we sample the first 
                    point on the path from a random light source). Once this sample is generated, we then trace the path until the end, in which the end is defined 
                    based on the Russian Roulette algorithm. For non-delta surfaces, we store the vertex in some sort of data structure (i.e. a “light path storage”) 
                    and join the vertex with the camera. Assuming that the path of the light isn’t too long, we can then sample a new point and continue to trace along 
                    the light path. 
                    <ul>
                        <li>
                            For this part, there was an additional helper method that helped generate the light sample that can be broken down in several parts:
                            <ul>
                                <li>First randomly choose a specific light in the scene.</li>
                                <li>Find the probability of light picking and scaling it accordingly with the sampling probability.</li>
                                <li>Shoot the ray in a random direction from the selected sampled point.</li>
                            </ul>
                        </li>
                    </ul>
                </li>
                <li>
                    For the “second” part of bidirectional path tracing, we want to generate an eye/camera sample. While similar to what is done for our light paths, 
                    the camera sample starts out from the camera instead of starting at a light source in the scene. In the case where the surface is non-delta, then we 
                    want to find the direct illumination from the hit point and find all the light paths that connect and intersect with the camera path. The direct 
                    illumination and areas of vertex connection are “accumulated” in a variable that keeps track of the color in the specific scene (based on the camera and 
                    light paths) and is stored later in the frame buffer. 
                    <ul>
                        <li>
                            We also created another method that helped us generate a camera sample. For this, we generated a specific pixel, and from the camera, we casted a 
                            ray towards the direction of the pixel based on its x and y coordinates.
                        </li>
                    </ul>
                </li>
            </ul>

            Here's the algorithm that we mainly used, to demonstrate the pseudocode from our source: 
          </p>

          <div id="centerImage">
			<img src="final_img/algorithm1.png" width="400px" style="margin: 5px 5px 5px 5px;">
            <figcaption> Algorithm from Bidirectional Path Tracing </figcaption>
		  </div> 

          <div class="row">
            <div class="column">
              <img src="final_img/algorithm2.png" width="370px" style="margin: 5px 5px 5px 50px;">
              <figcaption> Algorithm from Light Sampling </figcaption>
            </div>
            <div class="column">
              <img src="final_img/algorithm3.png" width="500px" style="margin: 5px 5px 5px 5px;">
              <figcaption> Algorithm from Camera/Eye Sample </figcaption>
            </div>
          </div>


          <h5>Problems Encountered</h5>
          <p>
            During our implementation of the project, we ran into multiple problems, the first involving our compilation of project 3. Because we needed to be able to 
            render glass and mirror materials, but also modify the path tracing technique, we needed a working p3-1 and p3-2. We found that our implementation of p3-1 was 
            not entirely working and had to ask for staff support on this, in which we were then able to fix our project and get the “starter” code working. After, when 
            implementing photon mapping, we ran into multiple issues regarding rendering. There were times where our lighting didn’t show the way we wanted to or it 
            didn’t end up showing at all. This required a lot of debugging sessions and also attendance in some office hours to figure out the issue, which was that the way the skeleton
            was set up, the spectrum of light sources doesn't get properly propegated down to the static light sources, resulting in our light sampling not working correctly. Additionally,
            our photon mapping ended up looking too rigid, likely because we werent attenuating the lighting contribution of the photon map correctly, so when averaging over the nearest photons, we
            end up with weird blocky lighting patterns because the nearest photons for multiple points are the same, even though some points are significantly further away from the photons, meaning they
            should not end up with the same photon map lighting contribution. The other difficulty we had was bidirectional path tracing, mainly because it was more complex conceptually than initially thought, 
            so there was more time spent on researching an implementation and figuring out how to integrate it into our code. To get a better grasp on bidirectional path tracing, we spent more 
            significant time on trying to understand the technique and then working on an implementation. 
          </p>
          
          <p>
            Ultimately, our implementation wasn’t perfect and had its flaws in rendering - while there was noticeable improvement in the amount of noise that was reduced in scenes, 
            it didn’t show the lighting in the scenes as accurately as we wanted to. There are some parts of the scene where the lighting didn’t exactly match up with the original 
            scene and while we are not entirely sure where the error is, we think it might have to do with our implementation of photon mapping - some possibilities might have to do with 
            our radiance estimate or our photon casting and the distribution of cast photons not being uniform throughout the scene geometry. 
          </p>

          <h5>Lessons Learned</h5>
          <p>
            In retrospect, while this project was very engaging, it had its difficulties - trying to combine both parts  for our VCM algorithm (photon mapping and 
            bidirectional path tracing) proved to be a challenge that demonstrated how much time it took to render images, especially when trying to render different 
            types of media and improve the overall path tracing technique. As mentioned earlier too, there was also difficulty in trying to get the implementation 
            together, as we had to figure out first to get a working version of the entirety of project 3 (both parts). Throughout the entire process of coding up the 
            implementation, we should’ve placed greater emphasis on debugging and also keeping track of images before and after our implementation, to check for frame 
            of reference if there were noticeable differences made by our implementation (which we did do, but would’ve helped if we had started a little earlier with this). 
            Overall though, we gained a greater understanding of not only the VCM algorithm, but also the techniques and algorithms that are behind rendering more complex 
            and unique media and their ability to do so. 
          </p>

          <!-- Results -->
          <h3>Results</h3>
          <p> 
            Below are our results with photon mapping. We show initially what the image looked like when rendering without photon mapping and bidirectional path tracing, 
            some images that were produced throughout the implementation and debugging process, and our final renders. 
          </p>

          <div class="row">
            <div class="column">
                <img src="final_img/original_spheres.png" width="500px" style="margin: 5px 5px 5px 5px;">
                <figcaption> Regular Path Tracing at 1024 Samples Per Pixel (CBspheres.dae)</figcaption>
            </div>
            <div class="column">
                <img src="final_img/original_lucy.png" width="500px" style="margin: 5px 5px 5px 5px;">
                <figcaption> Regular Path Tracing at 1024 Samples Per Pixel (CBlucy.dae) </figcaption>
            </div>
          </div>

          <p>
            Here are some images rendered throughout our process: 
          </p>

          <div id="centerImage">
			<img src="final_img/photon_mapping_bug1.png" width="500px" style="margin: 5px 5px 5px 5px;">
            <figcaption> (1) Initial Implementation of Photon Mapping </figcaption>
		  </div> 

          <div class="row">
            <div class="column">
              <img src="final_img/bdpt_bug1.png" width="480px" style="margin: 5px 5px 5px 50px;">
              <figcaption>(1) Initial Implementation of BDPT </figcaption>
            </div>
            <div class="column">
              <img src="final_img/bdpt_bug2.png" width="482px" style="margin: 5px 5px 5px 5px;">
              <figcaption>(2) Another Attempt at BDPT </figcaption>
            </div>
          </div>

          <p> Here are our final rendered images (while not perfect, did show a reduction of noise in the scenes): </p>

          <div class="row">
            <div class="column">
              <img src="final_img/final_spheres.png" width="480px" style="margin: 5px 5px 5px 50px;">
              <figcaption> Final Render of CBspheres.dae </figcaption>
            </div>
            <div class="column">
              <img src="final_img/final_lucy.png" width="487px" style="margin: 5px 5px 5px 5px;">
              <figcaption> Final Render of CBlucy.dae </figcaption>
            </div>
          </div>

          <!-- References -->
          <h3>References</h3>
          <p>
            <ul>
                <li><a href="https://graphics.stanford.edu/courses/cs348b-03/papers/veach-chapter10.pdf">Bidirectional Path Tracing</a></li>
                <li><a href="https://cescg.org/wp-content/uploads/2018/04/Vlnas-Bidirectional-Path-Tracing-1.pdf">Implementation for Bidirectional Path Tracing</a></li>
                <li><a href="https://github.com/SmallVCM/SmallVCM">A VCM Implementation</a></li>
                <li><a href="http://www.cs.cmu.edu/afs/cs/academic/class/15462-s15/www/lec_slides/lec16.pdf">Photon Mapping (CMU Lecture Slides 16)</a></li>
                <li><a href="https://www.cs.cmu.edu/afs/cs/academic/class/15462-s09/www/lec/17/lec17.pdf">Photon Mapping (CMU Lecture Slides 17)</a></li>
            </ul>
          </p>

          <!-- Contributions -->
          <h3>Contributions</h3>
          <p>
            <ul>
                <li>Nico: Wrote the design and implementation for photon-mapping, helped with BDPT debugging and proof-read the milestone and final webpage, created the final video. </li>
                <li>David: Contributed to photon-mapping debugging and implementation and created the slides for the final presentation.</li>
                <li>Jasmine: Helped with BDPT implementation, wrote the webpage for the proposal, milestone and webpage, created slides for final presentation. </li>
                <li>Jennifer: Wrote the implementation for BDPT and made the video for the milestone and final submission.</li>
            </ul>
          </p>

        </section>
		
		<hr class="divider">
		
		<!-- Final Project Video
		============================ -->
        <section id="idocs_navbar">
          <h2>Final Project Video </h2>
          <!-- Insert video link here as <a href> -->
          <p>
            Here is the link to our final video project, where we explain a high overview of our project and demonstrates the results: <a href="">video.</a>
          </p>

		</section>

		<hr class="divider">
		
		  
  
</div>
<!-- Document Wrapper end --> 

<!-- Back To Top --> 
<a id="back-to-top" data-toggle="tooltip" title="Back to Top" href="javascript:void(0)"><i class="fa fa-chevron-up"></i></a> 

<!-- JavaScript
============================ -->
<script src="assets/vendor/jquery/jquery.min.js"></script> 
<script src="assets/vendor/bootstrap/js/bootstrap.bundle.min.js"></script> 
<!-- Highlight JS -->
<script src="assets/vendor/highlight.js/highlight.min.js"></script> 
<!-- Easing --> 
<script src="assets/vendor/jquery.easing/jquery.easing.min.js"></script> 
<!-- Magnific Popup --> 
<script src="assets/vendor/magnific-popup/jquery.magnific-popup.min.js"></script> 
<!-- Custom Script -->
<script src="assets/js/theme.js"></script>
</body>
</html>
